{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbXhuePolXKL"
   },
   "source": [
    "# Boosting Exercise\n",
    "\n",
    "In this exercise, you will learn about the Boosting technique, which is an ensemble method used to primarily reduce bias, and also variance in supervised learning. It combines multiple weak learners into a single strong learner. The learners are trained sequentially, each trying to correct its predecessor.\n",
    "\n",
    "## Dataset\n",
    "We will use the Breast Cancer dataset for this exercise. This dataset contains features computed from digitized images of breast mass and is used to predict whether the mass is malignant or benign. **Feel free to use another dataset!!**\n",
    "\n",
    "## Task\n",
    "Your task is to:\n",
    "1. Load the dataset.\n",
    "2. Preprocess the data (if necessary).\n",
    "3. Implement boosting models.\n",
    "4. Evaluate the models performance.\n",
    "\n",
    "Please fill in the following code blocks to complete the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hTnB_ZUlo4l"
   },
   "source": [
    "## AdaBoost Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbOTwlJ4lx40"
   },
   "source": [
    "### Step 1: Import Required Libraries\n",
    "First, import the necessary libraries for data manipulation, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "JfWrWb4Wk8hH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUZB4tAnmLxP"
   },
   "source": [
    "### Step 2: Load and Preprocess the Dataset\n",
    "Load the dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "WVRRXzZDmOBO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(load_iris().data, columns = load_iris().feature_names)\n",
    "df['target'] = load_iris().target\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj1kXkthmcpv"
   },
   "source": [
    "### Step 3: Split the Dataset\n",
    "Split the dataset into training and testing sets to evaluate the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'target')\n",
    "y = df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "kKwDqYYrmeYQ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkGTqL6OmtXW"
   },
   "source": [
    "### Step 4: Initialize and Train the AdaBoost Classifier\n",
    "Initialize a Decision Tree classifier and use it as the base estimator for the AdaBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "V9SHMVeFmsfZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gemar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gemar\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 200)\n",
    "ada = AdaBoostClassifier(dt, n_estimators = 100, random_state = 33)\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyHWV9HRm0T0"
   },
   "source": [
    "## XGBoost Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqhPu5jfm8GB"
   },
   "source": [
    "### Step 1: Import Required Libraries\n",
    "First, import the necessary libraries for data manipulation, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "yDt8m9G9m6xA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ax-nGSfntwM"
   },
   "source": [
    "### Step 2: Load and Preprocess the Dataset\n",
    "Load the dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'target')\n",
    "y = df[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXX_PSXSoHmp"
   },
   "source": [
    "### Step 3: Split the Dataset\n",
    "Split the dataset into training and testing sets to evaluate the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Cdh8eq8zoIxi"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjBKszY3oN42"
   },
   "source": [
    "### Step 4: Initialize and Train the XGBoost Classifier\n",
    "Initialize and train the XGBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "zHkLiLENoRPe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators = 50, random_state = 30)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC5D5c0hoUVc"
   },
   "source": [
    "## Gradient Boosting Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8S9U-41oab4"
   },
   "source": [
    "### Step 1: Import Required Libraries\n",
    "First, import the necessary libraries for data manipulation, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "tJRkKxR9oYEK"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp5NR3ByoelM"
   },
   "source": [
    "### Step 2: Load and Preprocess the Dataset\n",
    "Load the dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "BPS8_qBrohcf"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'target')\n",
    "y = df[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVjHzyr7opoL"
   },
   "source": [
    "### Step 3: Split the Dataset\n",
    "Split the dataset into training and testing sets to evaluate the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IGe6bC74oq3q"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFkcaygKoyCG"
   },
   "source": [
    "### Step 4: Initialize and Train the Gradient Boosting Classifier\n",
    "Initialize and train the Gradient Boosting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "N4saJTWeoxwV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gemar\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators = 50, random_state = 5)\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred_gbc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
